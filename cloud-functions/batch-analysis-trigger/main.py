"""
Cloud Function - Activar An√°lisis para Transcripciones Existentes
Procesa todas las transcripciones sin an√°lisis
"""
import functions_framework
import requests
import logging
from google.cloud import bigquery

PROJECT_ID = "peak-emitter-350713"
DATASET_ID = "Calidad_Llamadas"
ANALYSIS_URL = "https://us-central1-peak-emitter-350713.cloudfunctions.net/analyze-quality"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@functions_framework.http
def trigger_batch_analysis(request):
    """
    HTTP Cloud Function para activar an√°lisis en lote
    """
    try:
        logger.info("üîÑ Iniciando an√°lisis en lote para transcripciones existentes...")
        
        # 1. Obtener todas las transcripciones sin an√°lisis
        client = bigquery.Client(project=PROJECT_ID)
        
        query = f"""
        SELECT t.dni, t.transcripcion_texto, t.audio_url
        FROM `{PROJECT_ID}.{DATASET_ID}.transcripciones` t
        LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.analisis_calidad` a 
            ON t.dni = a.dni AND t.audio_url = a.audio_url
        WHERE t.estado = 'procesado' 
        AND a.dni IS NULL
        ORDER BY t.created_at DESC
        LIMIT 500
        """
        
        result = client.query(query).to_dataframe()
        
        if result.empty:
            return {
                "success": True,
                "message": "No hay transcripciones pendientes de an√°lisis",
                "processed": 0
            }
        
        logger.info(f"üìã Encontradas {len(result)} transcripciones para analizar")
        
        # 2. Procesar cada transcripci√≥n
        processed = 0
        errors = 0
        
        for index, row in result.iterrows():
            try:
                dni = str(row['dni'])
                transcription_text = row['transcripcion_texto']
                
                success = trigger_single_analysis(dni, transcription_text)
                
                if success:
                    processed += 1
                    if processed % 10 == 0:
                        logger.info(f"‚úÖ Procesadas {processed}/{len(result)} transcripciones")
                else:
                    errors += 1
                    
            except Exception as e:
                errors += 1
                logger.error(f"‚ùå Error procesando DNI {row.get('dni', 'unknown')}: {str(e)}")
        
        logger.info(f"üéâ An√°lisis en lote completo: {processed} exitosas, {errors} errores")
        
        return {
            "success": True,
            "message": f"An√°lisis en lote completado: {processed}/{len(result)}",
            "processed": processed,
            "errors": errors,
            "total_found": len(result)
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error en an√°lisis en lote: {str(e)}")
        return {"error": str(e)}, 500

def trigger_single_analysis(dni, transcription_text):
    """Llamar a la funci√≥n de an√°lisis para una transcripci√≥n"""
    try:
        payload = {
            "dni": dni,
            "transcription": transcription_text
        }
        
        response = requests.post(
            ANALYSIS_URL,
            json=payload,
            timeout=120  # 2 minutos timeout
        )
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success', False):
                return True
            else:
                logger.error(f"‚ùå Error an√°lisis {dni}: {result.get('error', 'Unknown')}")
                return False
        else:
            logger.error(f"‚ùå HTTP {response.status_code} an√°lisis {dni}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Excepci√≥n an√°lisis {dni}: {str(e)}")
        return False